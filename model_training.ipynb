{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49904907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx import helper, numpy_helper, shape_inference\n",
    "import onnxruntime as ort\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b474a50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits source tensor: output\n",
      "Feats source tensor: /Flatten_output_0\n"
     ]
    }
   ],
   "source": [
    "ONNX_IN  = Path(\"/home/hschatzle/monte-carlo-selection/data/models/resnet50_tl_20250829.onnx\")\n",
    "ONNX_OUT = Path(\"/home/hschatzle/monte-carlo-selection/data/models/resnet50_tl_20250829_with_feats.onnx\")\n",
    "\n",
    "\n",
    "model = onnx.load(str(ONNX_IN))\n",
    "\n",
    "# logits tensor is the current graph output name (your model: \"output\")\n",
    "assert len(model.graph.output) == 1, \"Expected single output for logits\"\n",
    "logits_src = model.graph.output[0].name\n",
    "print(\"Logits source tensor:\", logits_src)\n",
    "\n",
    "# penultimate features tensor: last Flatten output (right before Gemm)\n",
    "flatten_nodes = [n for n in model.graph.node if n.op_type == \"Flatten\"]\n",
    "assert flatten_nodes, \"No Flatten node found\"\n",
    "feats_src = flatten_nodes[-1].output[0]\n",
    "print(\"Feats source tensor:\", feats_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b326bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/hschatzle/monte-carlo-selection/data/models/resnet50_tl_20250829_with_feats.onnx\n"
     ]
    }
   ],
   "source": [
    "# Cell 2. Add Identity heads for both outputs (stable naming) + set graph outputs (feats + logits)\n",
    "import onnx\n",
    "from onnx import helper, TensorProto, shape_inference\n",
    "\n",
    "# Infer shapes if possible (so outputs have known shapes)\n",
    "model_inf = shape_inference.infer_shapes(model)\n",
    "\n",
    "def find_vi(name: str):\n",
    "    # Search existing value_info / inputs / outputs\n",
    "    for vi in list(model_inf.graph.value_info) + list(model_inf.graph.input) + list(model_inf.graph.output):\n",
    "        if vi.name == name:\n",
    "            return vi\n",
    "    return None\n",
    "\n",
    "def make_output_vi(src_name: str, out_name: str):\n",
    "    vi = find_vi(src_name)\n",
    "    if vi is None:\n",
    "        # Fallback: unknown shape\n",
    "        return helper.make_tensor_value_info(out_name, TensorProto.FLOAT, None)\n",
    "\n",
    "    # Copy type/shape from src, but rename to out_name\n",
    "    t = vi.type.tensor_type\n",
    "    elem_type = t.elem_type\n",
    "    shape = [d.dim_value if d.dim_value > 0 else (d.dim_param if d.dim_param else None) for d in t.shape.dim]\n",
    "    # ONNX wants dim_value or dim_param, cannot mix None directly. If unknown, omit the whole shape.\n",
    "    if any(s is None for s in shape):\n",
    "        return helper.make_tensor_value_info(out_name, elem_type, None)\n",
    "    return helper.make_tensor_value_info(out_name, elem_type, shape)\n",
    "\n",
    "# Create explicit output names\n",
    "FEATS_OUT  = \"features\"\n",
    "LOGITS_OUT = \"logits\"\n",
    "\n",
    "# Add Identity nodes to expose them as named outputs\n",
    "id_feats  = helper.make_node(\"Identity\", inputs=[feats_src],  outputs=[FEATS_OUT],  name=\"ExposeFeats\")\n",
    "id_logits = helper.make_node(\"Identity\", inputs=[logits_src], outputs=[LOGITS_OUT], name=\"ExposeLogits\")\n",
    "\n",
    "model.graph.node.extend([id_feats, id_logits])\n",
    "\n",
    "# Replace graph outputs with both\n",
    "model.graph.ClearField(\"output\")\n",
    "model.graph.output.extend([\n",
    "    make_output_vi(feats_src, FEATS_OUT),\n",
    "    make_output_vi(logits_src, LOGITS_OUT),\n",
    "])\n",
    "\n",
    "onnx.save(model, str(ONNX_OUT))\n",
    "print(\"Saved:\", ONNX_OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08e0cb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      "  features ['batch_size', 2048] tensor(float)\n",
      "  logits ['batch_size', 54] tensor(float)\n",
      "\n",
      "Inputs:\n",
      "  input ['batch_size', 3, 224, 224] tensor(float)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3. Verify with ONNX Runtime\n",
    "import onnxruntime as ort\n",
    "\n",
    "sess = ort.InferenceSession(str(ONNX_OUT), providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "print(\"Outputs:\")\n",
    "for o in sess.get_outputs():\n",
    "    print(\" \", o.name, o.shape, o.type)\n",
    "\n",
    "print(\"\\nInputs:\")\n",
    "for i in sess.get_inputs():\n",
    "    print(\" \", i.name, i.shape, i.type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c6ba52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "M1 = Path(\"/home/hschatzle/monte-carlo-selection/data/models/resnet50_geirhos_tl_with_feats.onnx\")  # e.g. original\n",
    "M2 = Path(\"/home/hschatzle/monte-carlo-selection/data/models/resnet50_jangtong_tl_with_feats.onnx\")  # e.g. your modified one\n",
    "M3 = Path(\"/home/hschatzle/monte-carlo-selection/data/models/resnet50_tl_20250829_with_feats.onnx\")  # e.g. another baseline\n",
    "\n",
    "for p in [M1, M2, M3]:\n",
    "    assert p.exists(), f\"Missing: {p}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce879e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "MODEL: /home/hschatzle/monte-carlo-selection/data/models/resnet50_geirhos_tl_with_feats.onnx\n",
      "IR version: 6\n",
      "Opset imports: [('', 11)]\n",
      "Producer: pytorch 2.8.0\n",
      "\n",
      "Graph inputs:\n",
      "  ('input', 1, ['batch_size', 3, 224, 224])\n",
      "\n",
      "Graph outputs:\n",
      "  ('output', 1, ['batch_size', 54])\n",
      "  ('features', 1, ['batch_size', 2048])\n",
      "\n",
      "ORT inputs:\n",
      "  input ['batch_size', 3, 224, 224] tensor(float)\n",
      "\n",
      "ORT outputs:\n",
      "  output ['batch_size', 54] tensor(float)\n",
      "  features ['batch_size', 2048] tensor(float)\n",
      "\n",
      "Last 12 nodes:\n",
      " Relu -> ['/layer4/layer4/1/relu_2/Relu/Relu_output_0']\n",
      " Conv -> ['/layer4/layer4/2/conv1/Conv/Conv_output_0']\n",
      " Relu -> ['/layer4/layer4/2/relu/Relu/Relu_output_0']\n",
      " Conv -> ['/layer4/layer4/2/conv2/Conv/Conv_output_0']\n",
      " Relu -> ['/layer4/layer4/2/relu_1/Relu/Relu_output_0']\n",
      " Conv -> ['/layer4/layer4/2/conv3/Conv/Conv_output_0']\n",
      " Add -> ['/layer4/layer4/2/Add/Add_output_0']\n",
      " Relu -> ['/layer4/layer4/2/relu_2/Relu/Relu_output_0']\n",
      " GlobalAveragePool -> ['/avgpool/GlobalAveragePool/GlobalAveragePool_output_0']\n",
      " Flatten -> ['/Flatten/Flatten_output_0']\n",
      " Gemm -> ['output']\n",
      " Identity -> ['features']\n",
      "\n",
      "==========================================================================================\n",
      "MODEL: /home/hschatzle/monte-carlo-selection/data/models/resnet50_jangtong_tl_with_feats.onnx\n",
      "IR version: 6\n",
      "Opset imports: [('', 11)]\n",
      "Producer: pytorch 2.8.0\n",
      "\n",
      "Graph inputs:\n",
      "  ('input', 1, ['batch_size', 3, 224, 224])\n",
      "\n",
      "Graph outputs:\n",
      "  ('features', 1, ['batch_size', 2048])\n",
      "  ('logits', 1, ['batch_size', 54])\n",
      "\n",
      "ORT inputs:\n",
      "  input ['batch_size', 3, 224, 224] tensor(float)\n",
      "\n",
      "ORT outputs:\n",
      "  features ['batch_size', 2048] tensor(float)\n",
      "  logits ['batch_size', 54] tensor(float)\n",
      "\n",
      "Last 12 nodes:\n",
      " Conv -> ['/layer4/layer4/2/conv1/Conv/Conv_output_0']\n",
      " Relu -> ['/layer4/layer4/2/relu/Relu/Relu_output_0']\n",
      " Conv -> ['/layer4/layer4/2/conv2/Conv/Conv_output_0']\n",
      " Relu -> ['/layer4/layer4/2/relu_1/Relu/Relu_output_0']\n",
      " Conv -> ['/layer4/layer4/2/conv3/Conv/Conv_output_0']\n",
      " Add -> ['/layer4/layer4/2/Add/Add_output_0']\n",
      " Relu -> ['/layer4/layer4/2/relu_2/Relu/Relu_output_0']\n",
      " GlobalAveragePool -> ['/avgpool/GlobalAveragePool/GlobalAveragePool_output_0']\n",
      " Flatten -> ['/Flatten/Flatten_output_0']\n",
      " Gemm -> ['output']\n",
      " Identity -> ['features']\n",
      " Identity -> ['logits']\n",
      "\n",
      "==========================================================================================\n",
      "MODEL: /home/hschatzle/monte-carlo-selection/data/models/resnet50_tl_20250829_with_feats.onnx\n",
      "IR version: 6\n",
      "Opset imports: [('', 11)]\n",
      "Producer: pytorch 2.8.0\n",
      "\n",
      "Graph inputs:\n",
      "  ('input', 1, ['batch_size', 3, 224, 224])\n",
      "\n",
      "Graph outputs:\n",
      "  ('features', 1, ['batch_size', 2048])\n",
      "  ('logits', 1, ['batch_size', 54])\n",
      "\n",
      "ORT inputs:\n",
      "  input ['batch_size', 3, 224, 224] tensor(float)\n",
      "\n",
      "ORT outputs:\n",
      "  features ['batch_size', 2048] tensor(float)\n",
      "  logits ['batch_size', 54] tensor(float)\n",
      "\n",
      "Last 12 nodes:\n",
      " Conv -> ['/layer4/layer4.2/conv1/Conv_output_0']\n",
      " Relu -> ['/layer4/layer4.2/relu/Relu_output_0']\n",
      " Conv -> ['/layer4/layer4.2/conv2/Conv_output_0']\n",
      " Relu -> ['/layer4/layer4.2/relu_1/Relu_output_0']\n",
      " Conv -> ['/layer4/layer4.2/conv3/Conv_output_0']\n",
      " Add -> ['/layer4/layer4.2/Add_output_0']\n",
      " Relu -> ['/layer4/layer4.2/relu_2/Relu_output_0']\n",
      " GlobalAveragePool -> ['/avgpool/GlobalAveragePool_output_0']\n",
      " Flatten -> ['/Flatten_output_0']\n",
      " Gemm -> ['output']\n",
      " Identity -> ['features']\n",
      " Identity -> ['logits']\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "def dump_signature(onnx_path: Path):\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"MODEL:\", onnx_path)\n",
    "\n",
    "    m = onnx.load(str(onnx_path))\n",
    "\n",
    "    print(\"IR version:\", m.ir_version)\n",
    "    print(\"Opset imports:\", [(op.domain, op.version) for op in m.opset_import])\n",
    "    print(\"Producer:\", m.producer_name, m.producer_version)\n",
    "\n",
    "    def fmt_vi(vi):\n",
    "        tt = vi.type.tensor_type\n",
    "        dtype = tt.elem_type\n",
    "        shape = []\n",
    "        for d in tt.shape.dim:\n",
    "            if d.dim_param:\n",
    "                shape.append(d.dim_param)\n",
    "            else:\n",
    "                shape.append(d.dim_value if d.dim_value != 0 else \"?\")\n",
    "        return vi.name, dtype, shape\n",
    "\n",
    "    print(\"\\nGraph inputs:\")\n",
    "    for vi in m.graph.input:\n",
    "        print(\" \", fmt_vi(vi))\n",
    "\n",
    "    print(\"\\nGraph outputs:\")\n",
    "    for vi in m.graph.output:\n",
    "        print(\" \", fmt_vi(vi))\n",
    "\n",
    "    # ORT view (sometimes differs if shape info is missing)\n",
    "    sess = ort.InferenceSession(str(onnx_path), providers=[\"CPUExecutionProvider\"])\n",
    "    print(\"\\nORT inputs:\")\n",
    "    for i in sess.get_inputs():\n",
    "        print(\" \", i.name, i.shape, i.type)\n",
    "    print(\"\\nORT outputs:\")\n",
    "    for o in sess.get_outputs():\n",
    "        print(\" \", o.name, o.shape, o.type)\n",
    "\n",
    "    # Quick tail nodes (helps identify where outputs come from)\n",
    "    print(\"\\nLast 12 nodes:\")\n",
    "    for n in m.graph.node[-12:]:\n",
    "        print(f\" {n.op_type} -> {list(n.output)}\")\n",
    "\n",
    "dump_signature(M1)\n",
    "dump_signature(M2)\n",
    "dump_signature(M3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0088e8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /home/hschatzle/monte-carlo-selection/data/models/resnet50_geirhos_tl_CANON.onnx\n",
      "Wrote: /home/hschatzle/monte-carlo-selection/data/models/resnet50_jangtong_tl_CANON.onnx\n",
      "Wrote: /home/hschatzle/monte-carlo-selection/data/models/resnet50_tl_20250829_CANON.onnx\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import onnx\n",
    "from onnx import helper, TensorProto, shape_inference\n",
    "\n",
    "def canonicalize_outputs(\n",
    "    onnx_in: Path,\n",
    "    onnx_out: Path,\n",
    "    logits_src_tensor: str = \"output\",      # in your graphs, Gemm produces 'output'\n",
    "    features_tensor_name: str = \"features\", # your identity already uses this in all 3\n",
    "):\n",
    "    m = onnx.load(str(onnx_in))\n",
    "\n",
    "    # Infer shapes (nice-to-have for proper output metadata)\n",
    "    m_inf = shape_inference.infer_shapes(m)\n",
    "\n",
    "    def find_vi(name: str):\n",
    "        for vi in list(m_inf.graph.value_info) + list(m_inf.graph.input) + list(m_inf.graph.output):\n",
    "            if vi.name == name:\n",
    "                return vi\n",
    "        return None\n",
    "\n",
    "    def make_vi(src_name: str, out_name: str):\n",
    "        vi = find_vi(src_name)\n",
    "        if vi is None:\n",
    "            return helper.make_tensor_value_info(out_name, TensorProto.FLOAT, None)\n",
    "\n",
    "        tt = vi.type.tensor_type\n",
    "        elem = tt.elem_type\n",
    "        # If any dim is unknown, omit shape (keeps it permissive)\n",
    "        shape = []\n",
    "        for d in tt.shape.dim:\n",
    "            if d.dim_param or d.dim_value == 0:\n",
    "                return helper.make_tensor_value_info(out_name, elem, None)\n",
    "            shape.append(d.dim_value)\n",
    "        return helper.make_tensor_value_info(out_name, elem, shape)\n",
    "\n",
    "    # 1) Ensure we have a 'features' tensor somewhere.\n",
    "    # In your models, there is already: Identity -> ['features']\n",
    "    features_exists = any(\n",
    "        (features_tensor_name in node.output) for node in m.graph.node\n",
    "    ) or any(o.name == features_tensor_name for o in m.graph.output)\n",
    "\n",
    "    if not features_exists:\n",
    "        # Fallback: expose last Flatten as 'features'\n",
    "        flatten_nodes = [n for n in m.graph.node if n.op_type == \"Flatten\"]\n",
    "        if not flatten_nodes:\n",
    "            raise RuntimeError(\"No Flatten node found to derive features from.\")\n",
    "        feats_src = flatten_nodes[-1].output[0]\n",
    "        m.graph.node.append(\n",
    "            helper.make_node(\"Identity\", inputs=[feats_src], outputs=[features_tensor_name], name=\"ExposeFeatures\")\n",
    "        )\n",
    "\n",
    "    # 2) Make sure logits are exposed as 'output' (not 'logits').\n",
    "    # Your Gemm already outputs 'output' in all three models.\n",
    "    # But models 2/3 also add an Identity -> ['logits'] and declare graph output 'logits'.\n",
    "    # We'll simply set the graph outputs to the canonical pair.\n",
    "\n",
    "    # 3) Replace graph outputs with canonical order and names\n",
    "    m.graph.ClearField(\"output\")\n",
    "    m.graph.output.extend([\n",
    "        make_vi(logits_src_tensor, \"output\"),\n",
    "        make_vi(features_tensor_name, \"features\"),\n",
    "    ])\n",
    "\n",
    "    onnx.save(m, str(onnx_out))\n",
    "    return onnx_out\n",
    "\n",
    "# ---- run on your three models ----\n",
    "paths = [\n",
    "    Path(\"/home/hschatzle/monte-carlo-selection/data/models/resnet50_geirhos_tl_with_feats.onnx\"),\n",
    "    Path(\"/home/hschatzle/monte-carlo-selection/data/models/resnet50_jangtong_tl_with_feats.onnx\"),\n",
    "    Path(\"/home/hschatzle/monte-carlo-selection/data/models/resnet50_tl_20250829_with_feats.onnx\"),\n",
    "]\n",
    "\n",
    "for p in paths:\n",
    "    outp = p.with_name(p.stem.replace(\"_with_feats\", \"\") + \"_CANON.onnx\")\n",
    "    canonicalize_outputs(p, outp)\n",
    "    print(\"Wrote:\", outp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
